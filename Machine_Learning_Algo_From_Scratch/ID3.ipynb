{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import csv\n",
    "sys.__stdout__=sys.stdout\n",
    "\n",
    "def get_attr_names(df):\n",
    "    return list(df.columns.values)\n",
    "\n",
    "def get_possible_labels(examples,attr_name):     #getting possible labels of a attribute\n",
    "    attr_column=examples[attr_name]\n",
    "    labels=[]\n",
    "    for m in attr_column:\n",
    "        if m not in labels:\n",
    "            labels.append(m)\n",
    "    return(labels)\n",
    "    #return examples[attr_name].unique()\n",
    "\n",
    "def get_target_label_counts(target_attr,target_labels): #getting target label counts of a dataset\n",
    "    counts={}\n",
    "    for label in target_labels:\n",
    "        counts[label]=0\n",
    "    for j in target_attr.index:\n",
    "            target_val=target_attr[j]\n",
    "            for label in target_labels:\n",
    "                if target_val==label:\n",
    "                    counts[label]=counts[label]+1\n",
    "    return counts\n",
    "    #return dict(target_attr.value_counts())\n",
    "    \n",
    "def get_most_common(counts):\n",
    "    most_common=''\n",
    "    max_count=0\n",
    "    for kk,vv in counts.items():\n",
    "        if int(vv)>max_count:\n",
    "               most_common=kk\n",
    "               max_count=vv\n",
    "    return most_common\n",
    "    \n",
    "def entropy(counts):\n",
    "    total=0\n",
    "    ent=0\n",
    "    counts=list(counts.values())\n",
    "    total=np.sum(counts)\n",
    "    if total==0:\n",
    "        return ent\n",
    "    for val in counts:\n",
    "        p=val/total\n",
    "        if p!=0:\n",
    "            ent-=1*p*np.log2(p)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def gain(examples,attr_name,target_attr,target_labels):\n",
    "\n",
    "    tg_label_count=get_target_label_counts(target_attr,target_labels)            #Getting label(+/-/others) count for dataset/subset\n",
    "    ent_s=entropy(tg_label_count)                                                #Getting entropy for the dataset/subset\n",
    "    total_items=len(examples)                                                      #getting total items count in attrumn(attribute)\n",
    "    gain=0\n",
    "    split_info=0\n",
    "    labels=get_possible_labels(examples,attr_name)                                  #Getting possible labels for the attribute\n",
    "    for i in range(len(labels)):\n",
    "        _,target_attrVi=get_df_with_label(examples,target_attr,attr_name,labels[i]) #extract subset with label given\n",
    "        tg_label_count=get_target_label_counts(target_attrVi,target_labels)         #Getting label(+/-/others) count for dataset/subset                                                                    #Running iteration over splitted labels\n",
    "\n",
    "        ent=entropy(tg_label_count)                                                 #Getting entropy of each split\n",
    "        no_of_items=len(target_attrVi)                                                 #weighted sum of entropies of splits\n",
    "        ratio=no_of_items/total_items\n",
    "        gain=gain+ent*(ratio)\n",
    "\n",
    "        \n",
    "        if ratio!=0:\n",
    "            split_info-=(ratio*np.log2(ratio))                           #Getting weighted sum of split info\n",
    "            \n",
    "    gain=ent_s-gain                                                                #Getting information gain               \n",
    "    if split_info!=0:\n",
    "        gain_ratio=gain/split_info                                          \n",
    "    #print('Log ....',attr_name,ent_s,gain)\n",
    "    return split_info,gain\n",
    "\n",
    "def get_df_with_label(examples,target_attr,attr_name,label):                        \n",
    "    attr_attr=examples.loc[:,attr_name]                                  \n",
    "    ret=[]\n",
    "    for index in attr_attr.index:\n",
    "        if attr_attr[index]!=label:\n",
    "            ret.append(index)\n",
    "    examplesVi=examples.drop(ret,axis=0)\n",
    "    target_attrVi=target_attr.drop(ret)\n",
    "    return examplesVi,target_attrVi\n",
    "\n",
    "def get_thrsholds(df,attr_name,target_attr):\n",
    "        df[target_name]=target_attr\n",
    "        df_1=df.sort_values(attr_name,axis=0)               #Sorting value\n",
    "        target_attr_1=df_1[target_name]\n",
    "        prev_value=target_attr_1[target_attr_1.index.values[0]] #saving first value as previous value\n",
    "        thrs=[]                                                 #initializing variables\n",
    "        thrs_val=[]\n",
    "        summ=[]\n",
    "        i=0\n",
    "        #print(df_1)\n",
    "        for index in (target_attr_1.index):\n",
    "            thrs.append(index)                                        #saving values until any change in labels\n",
    "            if target_attr_1.loc[index]!=prev_value and len(thrs)>=2: #Comparing value with previous value\n",
    "                summ.append(thrs[:-1])                                #Saving the first group\n",
    "                temp=thrs[-1]\n",
    "                thrs=[]                                                 \n",
    "                thrs.append(temp)\n",
    "                val=df.loc[index,attr_name]                           #getting value of the threshold point \n",
    "                if val not in(thrs_val):                              #checking duplicate\n",
    "                    thrs_val.append(val)                                \n",
    "                prev_value=target_attr_1.loc[index]                   #\n",
    "        summ.append(thrs)\n",
    "        return(summ,thrs_val)                                       #returning threshold values and index\n",
    "                \n",
    "        #df get_splitted_gain\n",
    "\n",
    "\n",
    "def best_split(df,attr_name,target_attr,thrs_val):\n",
    "        df_left=df\n",
    "        df_right=df\n",
    "        wg_ent_sum=0\n",
    "        total_items=(len(df))\n",
    "        max_gain=0\n",
    "        best_thr=0\n",
    "        tg_label_count=get_target_label_counts(target_attr,target_labels)   #getting target labels counts\n",
    "        ent_s=entropy(tg_label_count)\n",
    "        print(len(thrs_val))\n",
    "        if len(thrs_val)>200:\n",
    "            thrs_val[0]=np.mean(thrs_val)\n",
    "            thrs_val=thrs_val[:1]\n",
    "        for val in thrs_val:                                                ####iteration over each threshold value\n",
    "            df_left=df\n",
    "            df_right=df\n",
    "            #val=thrs_val[0]\n",
    "            #for index,row in df.iterrows():                                 ####spliting for a threshold value\n",
    "            filt_left=df_left[attr_name]>=val\n",
    "            filt_right=df_right[attr_name]<val\n",
    "            df_left=df_left[filt_left]\n",
    "            df_right=df_right[filt_right]\n",
    "            df_list=[df_left,df_right]\n",
    "            wg_ent_sum=0\n",
    "            for sub_df in df_list:                                          #ierating over splited df\n",
    "                target_attrVi=sub_df[target_name]\n",
    "                tg_label_count=get_target_label_counts(target_attrVi,target_labels)\n",
    "                ent=entropy(tg_label_count)\n",
    "                no_items=len(target_attrVi)\n",
    "                wg_ent_sum+=(no_items/total_items)*ent                      ####Getting weighted sum for splited data\n",
    "            #print(ent_s,wg_ent_sum)\n",
    "            gain=ent_s-wg_ent_sum                                           ####Getting gain\n",
    "            if gain>max_gain:\n",
    "                max_gain=gain\n",
    "                best_thr=val                                                ####Getting thresh value with max gain\n",
    "            #print(gain,val,best_thr)\n",
    "        return best_thr\n",
    "        \n",
    "def relabel_attr(df,attr_name,best_thr):                                    \n",
    "    new_df=[]\n",
    "    for index,row in df.iterrows():\n",
    "        #print(df.loc[index,attr_name])\n",
    "        if (df.loc[index,attr_name]>best_thr):                          #Labeling values greater than threshold with descriptive string\n",
    "                new_df.append(attr_name+'>='+str(best_thr))\n",
    "        if (df.loc[index,attr_name]<=best_thr):                         #Labeling values less than threshold with descriptive string\n",
    "                new_df.append(attr_name+'<'+str(best_thr))\n",
    "    return new_df\n",
    "\n",
    "def discretize(df,attr_names,target_attr):\n",
    "    new_dict={}\n",
    "    max_label=25\n",
    "    for attr_name in attr_names:\n",
    "        lb=get_possible_labels(df,attr_name)\n",
    "        if(len(lb)>max_label) and df.dtypes[attr_name] !='object':\n",
    "            print(attr_name)\n",
    "            summ,thrs_val=get_thrsholds(df,attr_name,target_attr)\n",
    "            best_thr=best_split(df,attr_name,target_attr,thrs_val)\n",
    "            new_attr=relabel_attr(df,attr_name,best_thr)\n",
    "            new_dict[attr_name]=new_attr\n",
    "        else:\n",
    "            labels=get_possible_labels(df,attr_name)\n",
    "            lb_num=len(labels)\n",
    "            if lb_num<=max_label:\n",
    "                new_dict[attr_name]=list(df[attr_name])\n",
    "    #new_dict[target_name]=list(df.loc[:,target_name])\n",
    "    new_df=pd.DataFrame(new_dict)\n",
    "    return(new_df)\n",
    "\n",
    "def ID3(examples,target_attr,attr_names):\n",
    "    global summary,res\n",
    "    tg_label_count=get_target_label_counts(target_attr,target_labels)              ###Getting target label counts\n",
    "    total=len(target_attr)\n",
    "    for label,count in tg_label_count.items():                                     ###Check purity=1 for all target label\n",
    "        if count==total:\n",
    "           return label\n",
    "    most_common=get_most_common(tg_label_count)\n",
    "    if len(attr_names)==0:                                                          ###Check for empty dataset                  \n",
    "            return most_common\n",
    "    max_gain=-1                                                                     ###Getting attribute with highest gain\n",
    "    attr_name=''\n",
    "    for i in range(len(attr_names)):                                                 \n",
    "        _,gain_value= gain(examples,attr_names[i],target_attr,target_labels)\n",
    "        if gain_value>max_gain:\n",
    "            max_gain=gain_value\n",
    "            attr_name=attr_names[i]\n",
    "    print('attr_name',attr_name)\n",
    "    labels=get_possible_labels(examples,attr_name)                                      ###Getting possible labels for bes attribute\n",
    "    print('labels',labels)\n",
    "    for label in labels:\n",
    "        examplesVi,target_attrVi=get_df_with_label(examples,target_attr,attr_name,label)###Getting new subset of dataset\n",
    "        examplesVi=examplesVi.drop(attr_name,axis=1)                            \n",
    "        res.append(attr_name)                                                           ###returning attr_name,label pair\n",
    "        res.append(label)\n",
    "        attr_names=get_attr_names(examplesVi)\n",
    "        if len(attr_names)==0:# len(target_attrVi)>=2:                                    ###Checking for empty datasets                                                                                         #Getting most common label\n",
    "            return most_common\n",
    "        else:\n",
    "            ret=ID3(examplesVi,target_attrVi,attr_names)                                ###Calling ID3\n",
    "            if ret !=None:\n",
    "                res.append(target_name)\n",
    "                res.append(ret)\n",
    "                summary.append(res)\n",
    "                res=[]\n",
    "    return \n",
    "\n",
    "\n",
    "#print('ret',summary)\n",
    "\n",
    "def build_tree(summary):\n",
    "    root=summary[0][0]\n",
    "    for k in range(len(summary)):\n",
    "        if summary[k][0]==root:\n",
    "            temp=summary[k]\n",
    "        if summary[k][0]!=root:\n",
    "            #print(temp)\n",
    "            for t in range(len(temp)):\n",
    "                if temp[t]==summary[k][0]:\n",
    "                    temp=temp[:t]\n",
    "                    break\n",
    "            summary[k]=temp+summary[k]\n",
    "        print(summary[k])\n",
    "\n",
    "def predict(test_df,test_target,summary):\n",
    "    acc=0\n",
    "    for kk in range(len(test_df)):\n",
    "         test=test_df.loc[kk,:]\n",
    "         #print('..............',kk)\n",
    "         for i in range(len(summary)):\n",
    "            m=len(summary[i])                   #Taking a rule\n",
    "            for j in range(int(m/2)):\n",
    "                attr=summary[i][2*j]            #Taking a attr\n",
    "                lb=summary[i][2*j+1]            #Taking corresponding label\n",
    "                #print('attr',attr,'lb',lb)\n",
    "                if attr!=target_name:           #last node is not reached\n",
    "                   if test[attr] != lb:         #Checking test data having same label \n",
    "                        break                   #if not break and go for next rule\n",
    "            if attr == target_name:             #if test data satisfy have all the attr>> label in rule\n",
    "                pred_label=lb                          #setting result according to rule\n",
    "                true_label=test_target[kk]\n",
    "                #print(kk,'rule',i,test_target[kk],'res',res)\n",
    "                if true_label==pred_label:        #Checking results validity from true label\n",
    "                    acc=acc+1\n",
    "                    tp[pred_label]+=1\n",
    "                #break\n",
    "                if true_label!=pred_label:\n",
    "                     tn[pred_label]+=1\n",
    "                     fp[true_label]+=1\n",
    "                break                           \n",
    "            if attr==target_name:\n",
    "                break\n",
    "    accuracy=acc/len(test_df)*100\n",
    "    \n",
    "    for label in target_labels:\n",
    "            try:recall[label]=tp[label]/(tp[label]+tn[label])\n",
    "            except:0\n",
    "            try:precision[label]=tp[label]/(tp[label]+fp[label])\n",
    "            except:0\n",
    "            print(label,'precision',precision[label],'recall',recall[label])\n",
    "    \n",
    "    print('Summary : ','correct:',acc, 'total :',len(test_df),'accuracy :',acc/len(test_df)*100,'%')\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ID3_with_continuous_feature_support_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepal_L\n",
      "23\n",
      "Petal_L\n",
      "6\n",
      "['Sepal_L', 'Sepal_W', 'Petal_L', 'Petal_W'] ['setosa', 'versicolor', 'virginica']\n",
      "       Sepal_L  Sepal_W      Petal_L  Petal_W\n",
      "0  Sepal_L<5.6      3.5  Petal_L<3.0      0.2\n",
      "1  Sepal_L<5.6      3.0  Petal_L<3.0      0.2\n",
      "2  Sepal_L<5.6      3.2  Petal_L<3.0      0.2\n",
      "3  Sepal_L<5.6      3.1  Petal_L<3.0      0.2\n",
      "4  Sepal_L<5.6      3.6  Petal_L<3.0      0.2\n",
      "5  Sepal_L<5.6      3.9  Petal_L<3.0      0.4\n",
      "6  Sepal_L<5.6      3.4  Petal_L<3.0      0.3\n",
      "7  Sepal_L<5.6      3.4  Petal_L<3.0      0.2\n",
      "8  Sepal_L<5.6      2.9  Petal_L<3.0      0.2\n",
      "9  Sepal_L<5.6      3.1  Petal_L<3.0      0.1\n",
      "Press Enter to continue:a\n",
      "attr_name Petal_W\n",
      "labels [0.2, 0.4, 0.3, 0.1, 0.5, 0.6, 1.4, 1.5, 1.3, 1.6, 1.0, 1.1, 1.8, 1.2, 1.7, 2.5, 1.9, 2.1, 2.2, 2.0, 2.4, 2.3]\n",
      "attr_name Sepal_W\n",
      "labels [3.2, 3.1, 2.8, 3.0, 2.2, 2.5, 2.9]\n",
      "attr_name Sepal_L\n",
      "labels ['Sepal_L>=5.6']\n",
      "attr_name Petal_L\n",
      "labels ['Petal_L>=3.0']\n",
      "attr_name Sepal_W\n",
      "labels [3.2, 2.9, 2.5, 3.0]\n",
      "attr_name Sepal_L\n",
      "labels ['Sepal_L>=5.6', 'Sepal_L<5.6']\n",
      "['Petal_W', 0.2, 'Species', 'setosa']\n",
      "['Petal_W', 0.4, 'Species', 'setosa']\n",
      "['Petal_W', 0.3, 'Species', 'setosa']\n",
      "['Petal_W', 0.1, 'Species', 'setosa']\n",
      "['Petal_W', 0.5, 'Species', 'setosa']\n",
      "['Petal_W', 0.6, 'Species', 'setosa']\n",
      "['Petal_W', 1.4, 'Species', 'versicolor']\n",
      "['Petal_W', 1.5, 'Sepal_W', 3.2, 'Species', 'versicolor']\n",
      "['Petal_W', 1.5, 'Sepal_W', 3.1, 'Species', 'versicolor']\n",
      "['Petal_W', 1.5, 'Sepal_W', 2.8, 'Species', 'versicolor']\n",
      "['Petal_W', 1.5, 'Sepal_W', 3.0, 'Species', 'versicolor']\n",
      "['Petal_W', 1.5, 'Sepal_W', 2.2, 'Sepal_L', 'Sepal_L>=5.6', 'Petal_L', 'Petal_L>=3.0', 'Species', 'versicolor']\n",
      "['Petal_W', 1.5, 'Sepal_W', 2.5, 'Species', 'versicolor']\n",
      "['Petal_W', 1.5, 'Sepal_W', 2.9, 'Species', 'versicolor']\n",
      "['Petal_W', 1.3, 'Species', 'versicolor']\n",
      "['Petal_W', 1.6, 'Species', 'versicolor']\n",
      "['Petal_W', 1.0, 'Species', 'versicolor']\n",
      "['Petal_W', 1.1, 'Species', 'versicolor']\n",
      "['Petal_W', 1.8, 'Sepal_W', 3.2, 'Species', 'versicolor']\n",
      "['Petal_W', 1.8, 'Sepal_W', 2.9, 'Species', 'virginica']\n",
      "['Petal_W', 1.8, 'Sepal_W', 2.5, 'Species', 'virginica']\n",
      "['Petal_W', 1.8, 'Sepal_W', 3.0, 'Species', 'virginica']\n",
      "['Petal_W', 1.2, 'Species', 'versicolor']\n",
      "['Petal_W', 1.7, 'Sepal_L', 'Sepal_L>=5.6', 'Species', 'versicolor']\n",
      "['Petal_W', 1.7, 'Sepal_L', 'Sepal_L<5.6', 'Species', 'virginica']\n",
      "['Petal_W', 2.5, 'Species', 'virginica']\n",
      "['Petal_W', 1.9, 'Species', 'virginica']\n",
      "['Petal_W', 2.1, 'Species', 'virginica']\n",
      "['Petal_W', 2.2, 'Species', 'virginica']\n",
      "['Petal_W', 2.0, 'Species', 'virginica']\n",
      "['Petal_W', 2.4, 'Species', 'virginica']\n",
      "['Petal_W', 2.3, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "32\n",
      "Press Enter for reduced error pruninga\n",
      "['Petal_W', 0.2, 'Species', 'setosa']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 0.4, 'Species', 'setosa']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 0.3, 'Species', 'setosa']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 0.1, 'Species', 'setosa']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 0.5, 'Species', 'setosa']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 0.6, 'Species', 'setosa']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.4, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.5, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.5, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.5, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.5, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.5, 'Sepal_W', 2.2, 'Sepal_L', 'Sepal_L>=5.6', 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.5, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.5, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.3, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.6, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.0, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.1, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8518518518518519 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.8, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8416206261510129 recall 1.0\n",
      "Summary :  correct: 20 total : 30 accuracy : 66.66666666666666 %\n",
      "66.66666666666666\n",
      "['Petal_W', 1.8, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8429319371727748 recall 1.0\n",
      "Summary :  correct: 26 total : 30 accuracy : 86.66666666666667 %\n",
      "86.66666666666667\n",
      "['Petal_W', 1.8, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8441127694859039 recall 1.0\n",
      "Summary :  correct: 26 total : 30 accuracy : 86.66666666666667 %\n",
      "86.66666666666667\n",
      "['Petal_W', 1.8, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8451816745655608 recall 1.0\n",
      "Summary :  correct: 26 total : 30 accuracy : 86.66666666666667 %\n",
      "86.66666666666667\n",
      "['Petal_W', 1.2, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8454545454545455 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.7, 'Species', 'versicolor']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8457059679767104 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.7, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.84593837535014 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 2.5, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8461538461538461 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 1.9, 'Species', 'virginica']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8463541666666666 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 2.1, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8465408805031447 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 2.2, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8467153284671532 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 2.0, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8468786808009423 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 2.4, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8470319634703196 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "['Petal_W', 2.3, 'Species', 'virginica']\n",
      "setosa precision 0 recall 0\n",
      "versicolor precision 0 recall 0.0\n",
      "virginica precision 0.8471760797342193 recall 1.0\n",
      "Summary :  correct: 23 total : 30 accuracy : 76.66666666666667 %\n",
      "76.66666666666667\n",
      "summary [['Petal_W', 0.2, 'Species', 'setosa'], ['Petal_W', 0.4, 'Species', 'setosa'], ['Petal_W', 0.3, 'Species', 'setosa'], ['Petal_W', 0.1, 'Species', 'setosa'], ['Petal_W', 0.5, 'Species', 'setosa'], ['Petal_W', 0.6, 'Species', 'setosa'], ['Petal_W', 1.4, 'Species', 'versicolor'], ['Petal_W', 1.5, 'Sepal_W', 3.2, 'Species', 'versicolor'], ['Petal_W', 1.5, 'Sepal_W', 3.1, 'Species', 'versicolor'], ['Petal_W', 1.5, 'Sepal_W', 2.8, 'Species', 'versicolor'], ['Petal_W', 1.5, 'Sepal_W', 3.0, 'Species', 'versicolor'], ['Petal_W', 1.5, 'Sepal_W', 2.2, 'Sepal_L', 'Sepal_L>=5.6', 'Petal_L', 'Petal_L>=3.0', 'Species', 'versicolor'], ['Petal_W', 1.5, 'Sepal_W', 2.5, 'Species', 'versicolor'], ['Petal_W', 1.5, 'Sepal_W', 2.9, 'Species', 'versicolor'], ['Petal_W', 1.3, 'Species', 'versicolor'], ['Petal_W', 1.6, 'Species', 'versicolor'], ['Petal_W', 1.0, 'Species', 'versicolor'], ['Petal_W', 1.1, 'Species', 'versicolor'], ['Petal_W', 1.8, 'Sepal_W', 3.2, 'Species', 'versicolor'], ['Petal_W', 1.8, 'Sepal_W', 2.9, 'Species', 'virginica'], ['Petal_W', 1.8, 'Sepal_W', 2.5, 'Species', 'virginica'], ['Petal_W', 1.8, 'Sepal_W', 3.0, 'Species', 'virginica'], ['Petal_W', 1.2, 'Species', 'versicolor'], ['Petal_W', 1.7, 'Sepal_L', 'Sepal_L>=5.6', 'Species', 'versicolor'], ['Petal_W', 1.7, 'Sepal_L', 'Sepal_L<5.6', 'Species', 'virginica'], ['Petal_W', 2.5, 'Species', 'virginica'], ['Petal_W', 1.9, 'Species', 'virginica'], ['Petal_W', 2.1, 'Species', 'virginica'], ['Petal_W', 2.2, 'Species', 'virginica'], ['Petal_W', 2.0, 'Species', 'virginica'], ['Petal_W', 2.4, 'Species', 'virginica'], ['Petal_W', 2.3, 'Species', 'virginica']]\n",
      "i  22\n",
      "max_accuracy 86.66666666666667\n"
     ]
    }
   ],
   "source": [
    "#names=['A','B','C','D','E','F','G','H','I','J']\n",
    "df=pd.read_csv('Dataset/iris.csv',delimiter=',' )#,names=names)\n",
    "\n",
    "#df=df.sample(frac=1).reset_index(drop=True)\n",
    "#print(df.head(10))\n",
    "#input()\n",
    "df=df.fillna(df.mean())\n",
    "#df=df.replace(np.NaN,0)\n",
    "#df=df.drop('day',axis=1#df=df.drop('Ticket',axis=1)\n",
    "\n",
    "summary=[]\n",
    "res=[]\n",
    "attr_names=get_attr_names(df)\n",
    "target_name=attr_names[-1]\n",
    "target_attr=df[target_name]\n",
    "target_labels=get_possible_labels(df,target_name)\n",
    "\n",
    "tg_label_count=get_target_label_counts(target_attr,target_labels)\n",
    "most_common=get_most_common(tg_label_count)\n",
    "\n",
    "fp={}\n",
    "tn={}\n",
    "tp={}\n",
    "precision={}\n",
    "recall={}\n",
    "for label in target_labels:\n",
    "    fp[label]=0\n",
    "    tn[label]=0\n",
    "    tp[label]=0\n",
    "    recall[label]=0\n",
    "    precision[label]=0\n",
    "\n",
    "df=df.drop(target_name,axis=1)\n",
    "attr_names=attr_names[:-1]\n",
    "df=discretize(df,attr_names,target_attr)\n",
    "attr_names=get_attr_names(df)\n",
    "print(attr_names,target_labels)\n",
    "print(df.head(10))\n",
    "input('Press Enter to continue:')\n",
    "split=int(0.8*len(df))\n",
    "#split=0\n",
    "test_df=df.loc[split:,:]\n",
    "test_target=target_attr.loc[split:]\n",
    "test_df=test_df.reset_index(drop=True)\n",
    "test_target=test_target.reset_index(drop=True)\n",
    "#split=len(df)\n",
    "df=df.loc[:split,:]\n",
    "target_attr=target_attr.loc[:split]\n",
    "\n",
    "#for attr_name in attr_names:\n",
    "#    split_info,gain_value= gain(df,attr_name,target_attr,target_labels)\n",
    "#    print(attr_name,split_info)\n",
    "#    input()\n",
    "\n",
    "ID3(df,target_attr,attr_names)\n",
    "build_tree(summary)\n",
    "accuracy=predict(test_df,test_target,summary)\n",
    "print(len(summary))\n",
    "input('Press Enter for reduced error pruning')\n",
    "accuracy=0\n",
    "max_i=0\n",
    "max_acc=0\n",
    "max_summary=''\n",
    "\n",
    "for i in range(len(summary)):\n",
    "        temp_rule=summary[i]\n",
    "        if (len(summary[i])>4):\n",
    "            temp=summary[i][-2:]\n",
    "            summary[i]=summary[i][:-4]\n",
    "            summary[i]=summary[i]+temp\n",
    "        print(summary[i])\n",
    "        if accuracy>=max_acc:\n",
    "            max_acc=accuracy\n",
    "            max_summary=summary\n",
    "            max_i=i\n",
    "        accuracy=predict(test_df,test_target,summary)\n",
    "        print(accuracy)\n",
    "        summary[i]=temp_rule\n",
    "print('summary',max_summary)\n",
    "print('i ',max_i)\n",
    "print('max_accuracy',max_acc)\n",
    "#i  8\n",
    "#max_accuracy 66.76300578034682\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
