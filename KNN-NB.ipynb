{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "\n",
    "sys.__stdout__=sys.stdout\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    #text=re.sub('\\n',' ',text)\n",
    "    #text=re.sub('-',' ',text)\n",
    "    #text=re.sub('[\\'\"]','',text)\n",
    "    #text=re.sub('[()?.@*#&!,$]','',text)\n",
    "    text=re.sub('[^a-z0-9]',' ',text)\n",
    "    return text#TAG_RE.sub('', text)\n",
    "\n",
    "\n",
    "def make_dictionary(topics,max_doc,root):\n",
    "    index=0\n",
    "    wordmap={}\n",
    "    word_count=[]\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "        mydoc = minidom.parse(root+topic+'.xml')\n",
    "        docs = mydoc.getElementsByTagName('row')\n",
    "        doc_count=0\n",
    "        for doc in docs:\n",
    "            if doc_count>=max_doc:\n",
    "                break\n",
    "            doc=doc.attributes['Body'].value\n",
    "            doc=doc.lower()\n",
    "            doc = remove_tags(doc)\n",
    "            words=doc.split(' ')\n",
    "            for word in words:\n",
    "                word=ps.stem(word)\n",
    "                if word in s_words:\n",
    "                    continue\n",
    "                if word not in wordmap:\n",
    "                    wordmap[word]=index\n",
    "                    word_count.append(int(1))\n",
    "                    index=index+1\n",
    "                elif word in wordmap:\n",
    "                    ind=wordmap[word]\n",
    "                    word_count[ind]=int(word_count[ind])+1\n",
    "            doc_count=doc_count+1\n",
    "    return wordmap,word_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_seq_nb(topics,max_doc,wordmap,root,doc_per_vect='all'):\n",
    "    if doc_per_vect=='single':\n",
    "        n_row=len(topics)*(max_doc)\n",
    "    if doc_per_vect=='all':\n",
    "        n_row=len(topics)\n",
    "    vectors=np.zeros((n_row,len(wordmap)),dtype=np.float64)\n",
    "    vct_label=[]\n",
    "    row=0\n",
    "    _V=len(wordmap)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "        mydoc = minidom.parse(root+topic+'.xml')\n",
    "        docs = mydoc.getElementsByTagName('row')\n",
    "        doc_count=0\n",
    "        for doc in docs:\n",
    "            if doc_count>=max_doc:\n",
    "                break\n",
    "            #vector = [0]*(len(wordmap)+2)\n",
    "            doc=doc.attributes['Body'].value\n",
    "            doc=doc.lower()\n",
    "            doc = remove_tags(doc)\n",
    "            words=doc.split(' ')\n",
    "                     \n",
    "            if len(words)<5:\n",
    "                continue\n",
    "            for word in words:\n",
    "                word=ps.stem(word)\n",
    "                if word in wordmap:\n",
    "                    ind=wordmap[word]\n",
    "                    vectors[row,ind]=vectors[row,ind]+1\n",
    "            doc_count=doc_count+1\n",
    "            word_list.append(words)\n",
    "            if doc_per_vect=='single':\n",
    "                vct_label.append(topic)\n",
    "                row=row+1\n",
    "        if doc_per_vect=='all':\n",
    "            vct_label.append(topic)\n",
    "            #total=np.sum(vectors[row])\n",
    "            #vectors[row]=(vectors[row]+alpha)/(total+alpha*_V)\n",
    "            row=row+1\n",
    "    return vectors,vct_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d_Printer\n",
      "Coffee\n",
      "Arduino\n",
      "Astronomy\n",
      "Biology\n",
      "3d_Printer\n",
      "Coffee\n",
      "Arduino\n",
      "Astronomy\n",
      "Biology\n"
     ]
    }
   ],
   "source": [
    "root='Dataset/Training/'\n",
    "root_test='Dataset/Test/'\n",
    "f=open('Stopwords.txt')\n",
    "s_words=f.read()\n",
    "s_words=s_words.split('\\n')\n",
    "s_words.append('')\n",
    "\n",
    "topics=['3d_Printer','Coffee','Arduino','Astronomy','Biology']#,'Chess','Cooking','Law','Space','Windows_Phone','Wood_Working']\n",
    "#topics=['Anime']\n",
    "\n",
    "\n",
    " \n",
    "#wordmap=make_dictionary(topics,100,root)\n",
    "#vectors=vectorize_seq(topics,100,wordmap,root)\n",
    "word_list=[]\n",
    "write_backup=1\n",
    "max_docs_train=200\n",
    "if write_backup==1:\n",
    "    wordmap,wc=make_dictionary(topics,max_docs_train,root)\n",
    "    vectors,vct_labels=vectorize_seq_nb(topics,max_docs_train,wordmap,root)\n",
    "    pickle_out = open(\"wordmap_test.pickle\",\"wb\")\n",
    "    pickle.dump(wordmap, pickle_out)\n",
    "    pickle_out.close()\n",
    "    pickle_out = open(\"vectors_test.pickle\",\"wb\")\n",
    "    pickle.dump(vectors, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "read_backup=0\n",
    "if read_backup==1:\n",
    "    print('Reading backup')\n",
    "    pickle_read = open(\"wordmap_500.pickle\",\"rb\")\n",
    "    wordmap=pickle.load(pickle_read)\n",
    "    pickle_read.close()\n",
    "\n",
    "    pickle_read = open(\"vectors_500.pickle\",\"rb\")\n",
    "    vectors=pickle.load(pickle_read)\n",
    "    pickle_read.close()\n",
    "\n",
    "#words=list(wordmap.keys())\n",
    "#freq=list(wordmap.values())\n",
    "#word_df=pd.DataFrame({'words':words,'freq':freq})\n",
    "#word_df=word_df.sort_values('freq',ascending=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 35. 446.  38. ...   0.   0.   0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3d_Printer', 'Coffee', 'Arduino', 'Astronomy', 'Biology']\n",
      "8384\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print((vectors[0]))\n",
    "x=range(len(vectors[0]))\n",
    "plt.plot(x,vectors[0])\n",
    "plt.plot(x,vectors[2])\n",
    "#plt.plot(x,vectors[2])\n",
    "plt.show()\n",
    "print(vct_labels)\n",
    "print(len(wordmap))\n",
    "#no stem 500 20599 \n",
    "#stem 500 14883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d_Printer\n",
      "Coffee\n",
      "Arduino\n",
      "Astronomy\n",
      "Biology\n",
      "8384\n"
     ]
    }
   ],
   "source": [
    "max_docs_test=60\n",
    "test_vectors,true_lbs=vectorize_seq_nb(topics,max_docs_test,wordmap,root_test,doc_per_vect='single')\n",
    "def nb(test_vector,vectors,vct_labels,alpha):\n",
    "    probs=[]\n",
    "    maxm=0\n",
    "    lb=''\n",
    "    prob=0\n",
    "    vct=0\n",
    "    _vectors=vectors.copy()\n",
    "    for row in range(len(_vectors)):\n",
    "        len_of_wordmap=len(wordmap)\n",
    "        total_word=np.sum(_vectors[row])\n",
    "        _vectors[row]=(_vectors[row]+alpha)/(total_word+alpha*len_of_wordmap)\n",
    "    for row in range(len(_vectors)):\n",
    "        vect=_vectors[row]\n",
    "        vect[test_vector==0]=1\n",
    "        #test_vector_zero_mask=np.array(test_vector==0,dtype=np.uint8)\n",
    "        #test_vector_one_mask=np.array(test_vector!=0,dtype=np.uint8)\n",
    "        #vect=test_vector_one_mask*vectors[row]+test_vector_zero_mask\n",
    "        \n",
    "        prob=np.prod(vect)\n",
    "        probs.append(prob)\n",
    "        if prob>maxm:\n",
    "            maxm=prob\n",
    "            lb=vct_labels[row]\n",
    "    return probs,lb\n",
    "print(len(test_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.0 acc : 0.1705685618729097\n",
      "alpha:  0.01 acc : 0.8060200668896321\n",
      "alpha:  0.02 acc : 0.8093645484949833\n",
      "alpha:  0.03 acc : 0.8093645484949833\n",
      "alpha:  0.04 acc : 0.8127090301003345\n",
      "alpha:  0.05 acc : 0.8193979933110368\n",
      "alpha:  0.06 acc : 0.822742474916388\n",
      "alpha:  0.07 acc : 0.822742474916388\n",
      "alpha:  0.08 acc : 0.822742474916388\n",
      "alpha:  0.09 acc : 0.822742474916388\n",
      "alpha:  0.1 acc : 0.822742474916388\n",
      "alpha:  0.11 acc : 0.822742474916388\n",
      "alpha:  0.12 acc : 0.8260869565217391\n",
      "alpha:  0.13 acc : 0.8260869565217391\n",
      "alpha:  0.14 acc : 0.8260869565217391\n",
      "alpha:  0.15 acc : 0.822742474916388\n",
      "alpha:  0.16 acc : 0.822742474916388\n",
      "alpha:  0.17 acc : 0.822742474916388\n",
      "alpha:  0.18 acc : 0.822742474916388\n",
      "alpha:  0.19 acc : 0.822742474916388\n",
      "alpha:  0.2 acc : 0.822742474916388\n",
      "alpha:  0.21 acc : 0.822742474916388\n",
      "alpha:  0.22 acc : 0.822742474916388\n",
      "alpha:  0.23 acc : 0.822742474916388\n",
      "alpha:  0.24 acc : 0.822742474916388\n",
      "alpha:  0.25 acc : 0.822742474916388\n",
      "alpha:  0.26 acc : 0.822742474916388\n",
      "alpha:  0.27 acc : 0.822742474916388\n",
      "alpha:  0.28 acc : 0.822742474916388\n",
      "alpha:  0.29 acc : 0.822742474916388\n",
      "alpha:  0.3 acc : 0.822742474916388\n",
      "alpha:  0.31 acc : 0.822742474916388\n",
      "alpha:  0.32 acc : 0.822742474916388\n",
      "alpha:  0.33 acc : 0.822742474916388\n",
      "alpha:  0.34 acc : 0.822742474916388\n",
      "alpha:  0.35 acc : 0.822742474916388\n",
      "alpha:  0.36 acc : 0.822742474916388\n",
      "alpha:  0.37 acc : 0.822742474916388\n",
      "alpha:  0.38 acc : 0.822742474916388\n",
      "alpha:  0.39 acc : 0.822742474916388\n",
      "alpha:  0.4 acc : 0.822742474916388\n",
      "alpha:  0.41 acc : 0.822742474916388\n",
      "alpha:  0.42 acc : 0.822742474916388\n",
      "alpha:  0.43 acc : 0.822742474916388\n",
      "alpha:  0.44 acc : 0.822742474916388\n",
      "alpha:  0.45 acc : 0.8193979933110368\n",
      "alpha:  0.46 acc : 0.8193979933110368\n",
      "alpha:  0.47 acc : 0.8193979933110368\n",
      "alpha:  0.48 acc : 0.8193979933110368\n",
      "alpha:  0.49 acc : 0.8193979933110368\n",
      "alpha:  0.5 acc : 0.8193979933110368\n",
      "alpha:  0.51 acc : 0.8193979933110368\n",
      "alpha:  0.52 acc : 0.8193979933110368\n",
      "alpha:  0.53 acc : 0.8193979933110368\n",
      "alpha:  0.54 acc : 0.8193979933110368\n",
      "alpha:  0.55 acc : 0.8193979933110368\n",
      "alpha:  0.56 acc : 0.8193979933110368\n",
      "alpha:  0.57 acc : 0.8193979933110368\n",
      "alpha:  0.58 acc : 0.8193979933110368\n",
      "alpha:  0.59 acc : 0.8193979933110368\n",
      "alpha:  0.6 acc : 0.8193979933110368\n",
      "alpha:  0.61 acc : 0.8127090301003345\n",
      "alpha:  0.62 acc : 0.8127090301003345\n",
      "alpha:  0.63 acc : 0.8127090301003345\n",
      "alpha:  0.64 acc : 0.8127090301003345\n",
      "alpha:  0.65 acc : 0.8127090301003345\n",
      "alpha:  0.66 acc : 0.8127090301003345\n",
      "alpha:  0.67 acc : 0.8127090301003345\n",
      "alpha:  0.68 acc : 0.8127090301003345\n",
      "alpha:  0.69 acc : 0.8127090301003345\n",
      "alpha:  0.7 acc : 0.8127090301003345\n",
      "alpha:  0.71 acc : 0.8127090301003345\n",
      "alpha:  0.72 acc : 0.8127090301003345\n",
      "alpha:  0.73 acc : 0.8127090301003345\n",
      "alpha:  0.74 acc : 0.8127090301003345\n",
      "alpha:  0.75 acc : 0.8127090301003345\n",
      "alpha:  0.76 acc : 0.8127090301003345\n",
      "alpha:  0.77 acc : 0.8127090301003345\n",
      "alpha:  0.78 acc : 0.8127090301003345\n",
      "alpha:  0.79 acc : 0.8127090301003345\n",
      "alpha:  0.8 acc : 0.8127090301003345\n",
      "alpha:  0.81 acc : 0.8127090301003345\n",
      "alpha:  0.82 acc : 0.8127090301003345\n",
      "alpha:  0.83 acc : 0.8127090301003345\n",
      "alpha:  0.84 acc : 0.8127090301003345\n",
      "alpha:  0.85 acc : 0.8127090301003345\n",
      "alpha:  0.86 acc : 0.8127090301003345\n",
      "alpha:  0.87 acc : 0.8127090301003345\n",
      "alpha:  0.88 acc : 0.8127090301003345\n",
      "alpha:  0.89 acc : 0.8127090301003345\n",
      "alpha:  0.9 acc : 0.8127090301003345\n",
      "alpha:  0.91 acc : 0.8093645484949833\n",
      "alpha:  0.92 acc : 0.8093645484949833\n",
      "alpha:  0.93 acc : 0.8093645484949833\n",
      "alpha:  0.94 acc : 0.8093645484949833\n",
      "alpha:  0.95 acc : 0.8093645484949833\n",
      "alpha:  0.96 acc : 0.8093645484949833\n",
      "alpha:  0.97 acc : 0.8093645484949833\n",
      "alpha:  0.98 acc : 0.8093645484949833\n",
      "alpha:  0.99 acc : 0.8093645484949833\n",
      "alpha:  1.0 acc : 0.8093645484949833\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "alph=10\n",
    "no_topics=len(topics)\n",
    "tot_doc=no_topics*max_docs_train\n",
    "tot_doc_test=no_topics*max_docs_test\n",
    "acc_log=''\n",
    "acc_log+='******************************************************************\\n'\n",
    "acc_log+=str(topics)+'\\n'\n",
    "acc_log+=str(['no_topic','train doc per topic','train_doc','test doc per topic','test_doc','word map'])+'\\n'\n",
    "acc_log+=str([no_topics,max_docs_train,tot_doc,max_docs_test,tot_doc_test,str(len(wordmap))])+'\\n'\n",
    "acc_log+='******************************************************************\\n'\n",
    "acc_log+=str(['alpha','accuracy','time'])+'\\n'\n",
    "for al in range(101):\n",
    "    T=time.time()\n",
    "    acc=0\n",
    "    for i in range(len(test_vectors)):\n",
    "        alpha=al/100\n",
    "        pred,lb=nb(test_vectors[i],vectors,vct_labels,alpha)\n",
    "        if lb==true_lbs[i]:\n",
    "            acc=acc+1\n",
    "        #print('res','pred',lb,'true',true_lbs[i],i+1,acc)\n",
    "    T=time.time()-T\n",
    "    accuracy=acc/i\n",
    "    print('alpha: ',alpha,'acc :',accuracy)\n",
    "    \n",
    "    acc_log+=(str([alpha,accuracy,T])+'\\n')\n",
    "acc_log=re.sub('[\\[\\]]','',acc_log)\n",
    "f=open('nb_log.csv','a')\n",
    "f.write(acc_log)\n",
    "f.close()\n",
    "    #print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "246/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "[1 2 3 4 5 6] [  1   2 100   4   5   6]\n",
      "[[0 1 0 0 0 0]]\n",
      "10910624\n",
      "10910656\n",
      "10910656\n",
      "[1. 1. 2. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#print(word_list)\n",
    "d=np.array([1,2,3,4,5,6])\n",
    "print(d)\n",
    "k=d.copy()\n",
    "k[k==3]=100\n",
    "print(d,k)\n",
    "tv=vectors\n",
    "a=vectors[0,:]\n",
    "#print(len())\n",
    "print(np.array([k==2],dtype=np.uint8))\n",
    "var=8\n",
    "print(id(var))\n",
    "def v(var):\n",
    "    var=var+1\n",
    "    print(id(var))\n",
    "    return var\n",
    "var=v(var)\n",
    "print(id(var))\n",
    "v=np.ones(5)\n",
    "def func(v):\n",
    "    v[2]=v[2]+1\n",
    "    return 1\n",
    "func(v)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0  freq\n",
      "216         thi  2624\n",
      "8           use  2152\n",
      "4005      coffe  1773\n",
      "1999       code  1694\n",
      "1848    arduino  1190\n",
      "0         print   929\n",
      "90     question   800\n",
      "43         time   784\n",
      "258          ha   694\n",
      "37          ani   642\n",
      "77       differ   638\n",
      "601   blockquot   628\n",
      "404       water   522\n",
      "49         onli   504\n",
      "141        work   496\n",
      "657          wa   487\n",
      "379         way   483\n",
      "2112        amp   482\n",
      "5179       star   472\n",
      "13      printer   461\n",
      "2304        pin   458\n",
      "66         veri   449\n",
      "4232       brew   436\n",
      "2269      board   433\n",
      "2249        pre   425\n",
      "123      filter   394\n",
      "173         doe   388\n",
      "84     filament   379\n",
      "886        cell   367\n",
      "954       stack   360\n",
      "3575     serial   356\n",
      "55       becaus   349\n",
      "208     process   348\n",
      "4228       bean   346\n",
      "170        look   345\n",
      "296       gener   345\n",
      "4289    caffein   344\n",
      "9649     planet   343\n",
      "955       imgur   335\n",
      "291        good   332\n",
      "356      exampl   328\n",
      "112        mani   324\n",
      "578         bit   323\n",
      "346         tag   318\n",
      "174       chang   317\n",
      "2867      earth   316\n",
      "110     possibl   314\n",
      "4246      roast   311\n",
      "137       howev   308\n",
      "957         img   307\n"
     ]
    }
   ],
   "source": [
    "words=list(wordmap.keys())\n",
    "freq=list(wordmap.values())\n",
    "word_df=pd.DataFrame(words,index=list(wordmap.values()))\n",
    "word_df=word_df.sort_index()\n",
    "word_df['freq']=wc\n",
    "word_df=word_df.sort_values('freq',ascending=False)\n",
    "print(word_df[0:50])\n",
    "#print(len(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 12 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-63234f6ac4ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m498\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meucl_dis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 12 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "vct=[vectors[12][:500]]\n",
    "test=vectors[15][:498]\n",
    "dis=eucl_dis(test,vct)\n",
    "print(vct)\n",
    "print(test)\n",
    "print(dis[0][0])\n",
    "x=range(0,500)\n",
    "xt=range(0,498)\n",
    "plt.plot(x,vct[0],xt,test)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 'Coffee'], [4.1408162514693805, 'Coffee']]\n"
     ]
    }
   ],
   "source": [
    "def eucl_dis(test_vector,vectors):\n",
    "    h_dists=[]\n",
    "    for vector in vectors:\n",
    "        vect=np.array(vector[:-2])\n",
    "        vect[vect>1]=1\n",
    "        label=vector[-1]\n",
    "        test_vect=np.array(test_vector)\n",
    "        dist=np.abs(vect-test_vect)\n",
    "        #dist=np.sum(dist)\n",
    "        h_dists.append([dist,label])\n",
    "    return h_dists\n",
    "\n",
    "test_vector=vectors[0][:-2]\n",
    "vecto=[vectors[0],vectors[1]]\n",
    "h_dists=cos_dis(test_vector,vecto)\n",
    "#h_df=pd.DataFrame(h_dists)\n",
    "#h_df=h_df.sort_values(0)\n",
    "print(h_dists)\n",
    "#print((vectors[15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw='I am hasib\\n,i \"am\" a student() so? @i do& my-duties! porp. and' \n",
    "#text=re.sub('\\n',' ',raw)\n",
    "text=raw.lower()\n",
    "text=re.sub('[^a-z0-9]',' ',text)\n",
    "#text=re.sub('-',' ',text)\n",
    "#text=re.sub('[\\'\"]','',text)\n",
    "#text=re.sub('[()?.@*#&!,$+]','',text)\n",
    "#print(text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3\n"
     ]
    }
   ],
   "source": [
    "txt=(str([1,2,3]))\n",
    "txt=re.sub('[\\[\\]]','',txt)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
